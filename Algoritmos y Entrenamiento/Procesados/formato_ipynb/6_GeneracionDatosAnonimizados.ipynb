{"cells":[{"cell_type":"code","source":["# Importación de librerias\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport re\nfrom unicodedata import normalize\nfrom itertools import chain\nimport handyspark as hdy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sparkdl.xgboost import XgboostClassifier\n\nfrom pyspark.sql.types import StringType\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.functions import vector_to_array\nfrom pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, VectorSizeHint\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType, LongType, BooleanType, DoubleType, TimestampType\nfrom pyspark.sql.functions import desc, length, col,isnan,when,count\nimport pyspark.sql.functions as F\n\nimport mlflow\nimport mlflow.spark\n\nfrom hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\nfrom hyperopt.pyll import scope\nfrom math import exp\nfrom mlflow.models.signature import infer_signature\nfrom sklearn.metrics import roc_auc_score, balanced_accuracy_score, confusion_matrix, classification_report, confusion_matrix"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db47256b-f6ac-4462-8099-55ed98843771"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# 1) Guardado de datos necesarios para entrenamiento de modelos, excepto DescripcionPeticion"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8f81122-9620-4663-904f-227015c3bb29"}}},{"cell_type":"code","source":["# Solamente se subirá el 20% de los datos necesarios para replicar el entrenamiento de los datos, por lo que se parte del conjunto de datos cruzados y limpios luego de su procesamiento por los notebooks \"1_Importacion y cruce\" y \"2_Limpieza y creacion de variables\"\n\n# Leer archivo parquet donde se encuentra la base limpia\nfile = \"/mnt/basecruzada/baselimpia.parquet\"\nDF_modelo = spark.read.parquet(file)\n\n# Se dejan solo registros de mayo 2020 para atrás, ya que fueron estos los utilizados en los modelos de ML \nprint((DF_modelo.count(), len(DF_modelo.columns)))\nDF_modelo = DF_modelo.filter((col(\"AnoRegistroPeticion\") != \"2021\"))\nprint((DF_modelo.count(), len(DF_modelo.columns)))\nDF_modelo = DF_modelo.filter((col(\"AnoRegistroPeticion\") != \"2020\") | ~(col(\"MesRegistroPeticion\").isin([\"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\",\"Nov\",\"Dec\"])))\nprint((DF_modelo.count(), len(DF_modelo.columns)))\n\n# Seleccionar solo columnas necesarias para entrenamiento de modelo\ncolumnas_mantener = ['AnoRegistroPeticion', 'horaRegistroPeticion', 'minutoRegistroPeticion', 'X', 'Y', 'porc_etnica_2018', 'porc_indigena_2018', 'tasa_vip_total', 'tasa_vif_total', 'TasaFecunidad_15a19', 'porc_rural', 'vict_delsexual_total', 'EdadAfectado_Anios_Imputada', 'MesRegistroPeticion', 'MotivoPeticion', \"TipoPeticion\", 'CanalRecepcion','TipoDocumentoPeticionario', 'EdadPeticionario', 'SexoPeticionario', \"DetalleZonaPeticionario\", 'TipoDocumentoAfectado', 'SexoAfectado', \"DetalleZonAfectado\", 'GrupoEtnicoAfectado', 'PresentaDiscapacidadAfectado', 'CondicionDesplazamientoAfectado', 'PaisAfectado_5', \"CategorizacionPeticionario\", \"SinSuficienteInfo_Afectado\", 'DescripcionPeticion', 'VAR_OBJETIVO']\n\nDF_modelo = DF_modelo.select(columnas_mantener)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf54eb21-e2d6-420c-88ff-293d78a7767e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">(1163243, 118)\n(1088405, 118)\n(982085, 118)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(1163243, 118)\n(1088405, 118)\n(982085, 118)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Se realiza un muestreo estratificado del 20% de los registros. La estratificación se realiza por categoría de la variable objetivo, para que de para cada categoría se tome el 20% de los datos\nmuestra = DF_modelo.sampleBy(\"VAR_OBJETIVO\", fractions={\"verdadera_nopard\": 0.2, \"falsa\": 0.2, \"sindefinir_fallida\":0.2, \"verdadera_pard_noinst\":0.2, \"verdadera_pard_inst\":0.2}, seed=5)\nprint((muestra.count(), len(muestra.columns)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce42c07a-b03d-492b-94f3-9077b5d33c0f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">(196858, 32)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(196858, 32)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Se separa la columna de \"DescripcionPeticion\", ya que esta contiene información sensible y no puede ser difundida tal como está. Todas las otras columnas contienen información que no permite la identificación particular de una persona\nmuestra_sinDescripcion = muestra.drop(\"DescripcionPeticion\")\nmuestra_Descripcion = muestra.select(\"DescripcionPeticion\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23af9a51-6ee0-4a50-913b-36a5d8f0374e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Los datos sin la Descripción se pueden exportar directamente\nfile_location = \"/mnt/basecruzada/Muestra_DatosAbiertos/datos_modelo_sinDescripcion\"\nmuestra_sinDescripcion.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").mode(\"overwrite\").parquet(file_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb1d261f-53aa-46a4-b34c-93722d326bc3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# 2) Guardado de features/variables creadas a partir del texto de DescripcionPeticion\nLos datos de descripción no se exportarán directamente, sino que se transforman en features mediante distintos métodos"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfae8903-8a00-4df8-afe2-7e53045230e6"}}},{"cell_type":"markdown","source":["## 2.1) Guardado mediante conteo de palabras más frecuentes\nEl primero de los métodos en el que se extraen variables a partir del texto es el utilizado para el entrenamiento de redes neuronales, que cuenta el número de veces que en cada descripción aparecen las 200 palabras más frecuentes en todo el corpus"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fd31ba5-2ee4-4300-9ddd-af8f117441f1"}}},{"cell_type":"code","source":["# Esta transformación fue guardada mediante MLflow como un pipeline de Sklearn, por lo que es necesario importarlo\nsaved_text_pipeline = 'runs:/38239dc6bb4349d1b563ec5aa5928002/nn_text_pipeline'\ntext_pipeline = mlflow.sklearn.load_model(saved_text_pipeline)\n\n# La columna de texto se debe transformar a Pandas\nmuestra_Descripcion_pd = muestra_Descripcion.toPandas()\n\n# Debido a que hay algunas descripciones que están vacías, estas deben llenar con el texto \"(Vacío)\"\nmuestra_Descripcion_pd = muestra_Descripcion_pd.fillna(\"\")\n\n# Hacer transformación de texto en padded_sequence con pipeline importado\npadded_sequence = text_pipeline.transform(muestra_Descripcion_pd[\"DescripcionPeticion\"])\n\n# El resultado de la línea anterior es un array de Numpy de tamaño (196858, 200). Para poder guardarlos se transformarán a un Dataframe de Pandas, para lo que primero se crea una lista con el nombre de las columnas del dataframe que será [tokenizer_0, tokenizer_1, ... , tokenizer_199]\ntokenizer_columns = [\"textfeature_\"+ str(i) for i in range(200)]\n\n# Ahora se crea el Dataframe\nfinal_tokenizer_pd = pd.DataFrame(data=padded_sequence, columns=tokenizer_columns)\n\n# Se transforma este Pandas Dataframe a un Spark Dataframe para guardar estos datos de forma similar que los otros datos en formato parquet\nfinal_tokenizer = spark.createDataFrame(final_tokenizer_pd)\n\n# Se guarda como archivo Parquet en el Storage Account\nfile_location = \"/mnt/basecruzada/Muestra_DatosAbiertos/datos_modelo_Descripcion_tokenizer\"\nfinal_tokenizer.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").mode(\"overwrite\").parquet(file_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00e68be2-ed01-4b6f-b16f-323b6089e8f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 2.2) Guardado mediante TD-IDF\nAhora se exportarán las variables extraídas del texto mediante el método de TD-IDF, aplicado en el notebook \"3_PipelineSpark_TFIDF_Embedding\" y que es el utilizado para el entrenamiento de Gradient Boosted Trees con XGBoost en los notebooks \"4.3_ML_XGBoost_TFIDF_Weights\" y '4.4_ML_XGBoost_TFIDF_NoWeights'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8705302-182b-4a97-b44e-ec0d98ce28a4"}}},{"cell_type":"code","source":["# Esta transformación fue guardada mediante MLflow como un pipeline de SparkML, por lo que es necesario importarlo\n# Se carga el pipeline entrenado en el cuadernillo \"3_PipelineSpark_TFIDF_Embedding\", el correspondiente al TF-IDF que genera 300 features/variables \npipeline_tfidf = mlflow.spark.load_model(\"runs:/02cee8d29a894ebc86ace1eb965e0d12/tfidf_text_featuriser\")\n\n# Se transformar el texto en variables haciendo transform con el pipeline importado. Solo se mantiene la columna llamada \"tfidf\"\ntfidf_muestra_Descripcion = pipeline_tfidf.transform(muestra_Descripcion).select(\"tfidf\")\n\n# La columna \"tfidf\" contiene las variables creadas a partir del texto como un vector disperso de largo 300, se deben transformar a distintas columnas para guardarlo como archivo parquet\ntfidf_muestra_Descripcion = tfidf_muestra_Descripcion.withColumn(\"tfidf\", vector_to_array(\"tfidf\")).select([col(\"tfidf\")[i] for i in range(300)])\n\ntfidf_muestra_Descripcion.cache()\nprint(tfidf_muestra_Descripcion.count())\n\n# Se guarda como archivo Parquet en el Storage Account\nfile_location = \"/mnt/basecruzada/Muestra_DatosAbiertos/datos_modelo_Descripcion_tfidf\"\ntfidf_muestra_Descripcion.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").mode(\"overwrite\").parquet(file_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5d053dd-4227-4966-b538-09c7c3fc4766"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2021/10/04 03:14:27 INFO mlflow.spark: &#39;runs:/02cee8d29a894ebc86ace1eb965e0d12/tfidf_text_featuriser&#39; resolved as &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/02cee8d29a894ebc86ace1eb965e0d12/artifacts/tfidf_text_featuriser&#39;\n2021/10/04 03:14:27 INFO mlflow.spark: File &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/02cee8d29a894ebc86ace1eb965e0d12/artifacts/tfidf_text_featuriser/sparkml&#39; not found on DFS. Will attempt to upload the file.\n2021/10/04 03:15:03 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/a19c9ce6-f460-49d5-8cf9-d4a91e275581\n196858\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2021/10/04 03:14:27 INFO mlflow.spark: &#39;runs:/02cee8d29a894ebc86ace1eb965e0d12/tfidf_text_featuriser&#39; resolved as &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/02cee8d29a894ebc86ace1eb965e0d12/artifacts/tfidf_text_featuriser&#39;\n2021/10/04 03:14:27 INFO mlflow.spark: File &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/02cee8d29a894ebc86ace1eb965e0d12/artifacts/tfidf_text_featuriser/sparkml&#39; not found on DFS. Will attempt to upload the file.\n2021/10/04 03:15:03 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/a19c9ce6-f460-49d5-8cf9-d4a91e275581\n196858\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 2.3) Guardado mediante Word Embeddings\nAhora se exportarán las variables extraídas del texto mediante el método de Word Embeddings, que fue aplicado en el notebook \"3_PipelineSpark_TFIDF_Embedding\" y que es el utilizado para el entrenamiento de Gradient Boosted Trees con XGBoost en el notebook \"4.2_ML_XGBoost_Embedding_Weights\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd53ab13-4aac-4ede-81c1-fbead68915f2"}}},{"cell_type":"code","source":["# Esta transformación fue guardada mediante MLflow como un pipeline de SparkML, por lo que es necesario importarlo\n# Se carga el pipeline entrenado en el cuadernillo \"3_PipelineSpark_TFIDF_Embedding\", el correspondiente al Word Embedding que genera 100 features/variables \npipeline_wemb = mlflow.spark.load_model(\"runs:/abd6d3995aaf4c65b2577b73a9be62cf/word_embedding_text_featuriser\")\n\n# Se transformar el texto en variables haciendo transform con el pipeline importado. Solo se mantiene la columna llamada \"finished_embeddings_vector\"\nwemb_muestra_Descripcion = pipeline_wemb.transform(muestra_Descripcion).select(\"finished_embeddings_vector\")\n\n# La columna \"finished_embeddings_vector\" contiene las variables creadas a partir del texto como un vector disperso de largo 100, se deben transformar a distintas columnas para guardarlo como archivo parquet\nwemb_muestra_Descripcion = wemb_muestra_Descripcion.withColumn(\"finished_embeddings_vector\", vector_to_array(\"finished_embeddings_vector\")).select([col(\"finished_embeddings_vector\")[i] for i in range(100)])\n\nwemb_muestra_Descripcion.cache()\nprint(wemb_muestra_Descripcion.count())\n\n# Se guarda como archivo Parquet en el Storage Account\nfile_location = \"/mnt/basecruzada/Muestra_DatosAbiertos/datos_modelo_Descripcion_wordembeddings\"\nwemb_muestra_Descripcion.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").mode(\"overwrite\").parquet(file_location)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1bf300b-9ca4-45ec-92d7-33d96a47667b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2021/10/04 03:25:12 INFO mlflow.spark: &#39;runs:/abd6d3995aaf4c65b2577b73a9be62cf/word_embedding_text_featuriser&#39; resolved as &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/abd6d3995aaf4c65b2577b73a9be62cf/artifacts/word_embedding_text_featuriser&#39;\n2021/10/04 03:25:13 INFO mlflow.spark: File &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/abd6d3995aaf4c65b2577b73a9be62cf/artifacts/word_embedding_text_featuriser/sparkml&#39; not found on DFS. Will attempt to upload the file.\n2021/10/04 03:25:59 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/ba817413-c167-4e44-bfb0-b0765806982e\n196858\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2021/10/04 03:25:12 INFO mlflow.spark: &#39;runs:/abd6d3995aaf4c65b2577b73a9be62cf/word_embedding_text_featuriser&#39; resolved as &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/abd6d3995aaf4c65b2577b73a9be62cf/artifacts/word_embedding_text_featuriser&#39;\n2021/10/04 03:25:13 INFO mlflow.spark: File &#39;dbfs:/databricks/mlflow-tracking/3030803122807175/abd6d3995aaf4c65b2577b73a9be62cf/artifacts/word_embedding_text_featuriser/sparkml&#39; not found on DFS. Will attempt to upload the file.\n2021/10/04 03:25:59 INFO mlflow.spark: Copied SparkML model to /tmp/mlflow/ba817413-c167-4e44-bfb0-b0765806982e\n196858\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"6_GeneracionDatosAnonimizados","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":114289541097354}},"nbformat":4,"nbformat_minor":0}
