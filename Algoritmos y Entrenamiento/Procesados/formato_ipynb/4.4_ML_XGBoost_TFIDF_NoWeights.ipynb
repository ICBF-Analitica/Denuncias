{"cells":[{"cell_type":"code","source":["# Importación de librerias\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport re\nfrom unicodedata import normalize\nfrom itertools import chain\nimport handyspark as hdy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sparkdl.xgboost import XgboostClassifier\n\nfrom pyspark.sql.types import StringType\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.functions import vector_to_array\nfrom pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, VectorSizeHint\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType, LongType, BooleanType, DoubleType, TimestampType\nfrom pyspark.sql.functions import desc, length, col,isnan,when,count\nimport pyspark.sql.functions as F\n\nimport mlflow\nimport mlflow.spark\n\nfrom hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\nfrom hyperopt.pyll import scope\nfrom math import exp\nfrom mlflow.models.signature import infer_signature\nfrom sklearn.metrics import roc_auc_score, balanced_accuracy_score, confusion_matrix, classification_report, confusion_matrix"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4546b47f-a8c1-475d-9805-0a2036ecc62c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# # Parámetros para enlazar al Storage Account\n# storage_account = \"blobName\"\n# container = \"basecruzada\"\n# blobKey = \"blobKey\"\n# blobEndpoint = \"wasbs://{1}@{0}.blob.core.windows.net/\".format(storage_account, container)\n\n# try:\n#   dbutils.fs.mount(\n#     source = blobEndpoint,\n#     mount_point = \"/mnt/basecruzada\",\n#     extra_configs = {\"fs.azure.account.key.{0}.blob.core.windows.net\".format(storage_account):blobKey})\n# except:\n#   print(\"Already mounted. Unmounting and trying to mount again\")\n#   dbutils.fs.unmount(mount_point='/mnt/basecruzada')\n#   dbutils.fs.mount(\n#     source = blobEndpoint,\n#     mount_point = \"/mnt/basecruzada\",\n#     extra_configs = {\"fs.azure.account.key.{0}.blob.core.windows.net\".format(storage_account):blobKey})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0cde4479-e167-4123-8389-527d828cef12"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Already mounted. Unmounting and trying to mount again\n/mnt/sample has been unmounted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Already mounted. Unmounting and trying to mount again\n/mnt/sample has been unmounted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Para el entrenamiento de este modelo no es necesario hacer de nuevo el preprocesamiento de los datos, ya que este fue realizado previamente en el cuadernillo \"4.3_ML_XGBoost_TFIDF_Weights\" y se guardaron los datos de Entrenamiento y Evaluación en el Storage Account, por lo que ahora solo es necesario importar esos datos ya listos\n\nfile_train = \"/mnt/basecruzada/train_data_tfidf\"\ntrain_sdf_prepared = spark.read.parquet(file_train)\n\nfile_test = \"/mnt/basecruzada/test_data_tfidf\"\ntest_sdf_prepared = spark.read.parquet(file_test)\n\ntrain_sdf_prepared.cache()\ntest_sdf_prepared.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"12614804-939c-4af3-9da5-ad57dc12845e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[11]: DataFrame[features: vector, VAR_OBJETIVO: int, weights: double]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: DataFrame[features: vector, VAR_OBJETIVO: int, weights: double]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Aquí se define el espacio para la búsqueda de hiperparámetros de XGBOoost con HyperOpt.\nspark_model_name = \"xgboost_noweights_tfidf\"\n\nsearch_space = {\n  'max_depth': scope.int(hp.quniform('max_depth', 4, 15, 1)),\n  'eta': hp.loguniform('eta', -3, 0),\n  'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n  'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n  'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n  'subsample': hp.uniform('subsample', 0.5, 1),\n  'objective': 'multi:softmax',\n  'seed': 5,\n  \"missing\":0.0,\n  \"num_class\": 5,\n  \"num_round\": 1000,\n  \"num_workers\": 3,\n  \"tree_method\" : \"gpu_hist\",\n  \"use_gpu\": True,\n  \"verbosity\":2,\n  \"random_state\": 5\n}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"062151ab-4b88-42af-a3a4-251da6c2f59b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# El entrenamiento es similar al del cuadernillo \"4.3_ML_XGBoost_TFIDF_Weights\", la única diferencia es que en este caso al declarar el modelo XgboostClassifier no se incluirá el parámetro weightCol, pues este entrenamiento no incluirá los pesos de acuerdo a la categoría de la Variable Objetivo\n\n# Se define una función que HyperOpt utilizará para entrenar distintos modelos de XGBoost con distintas combinaciones de hiperparámetros.\n# Dentro del modelo de XgboostClassifier se define cuál es la columna del dataframe que contiene las features (featuresCol), la variable objetivo (labelCol),  la columna que indica si la observación es de Entrenamiento o Validación (validationIndicatorCol). También se define allí el nombre de las dos columnas que resultarán al hacer el predict con el modelo entrenado, \"prediction\" que contendrá la categoría predicha y \"probability\" que es un vector de tamaño 5 en el que está la probabilidad asignada a cada categoría del modelo\n# MLflow se empleará para hacer un registro de los modelos entrenados, los hiperparámetros usados para cada uno y las métricas calculadas sobre el conjunto de Evaluación para cada modelo y así poderlos comparar posteriormente\ndef train_model(xgbParams):\n  with mlflow.start_run(nested=True):\n    print(\"Start training\")\n    xgb = (\n      XgboostClassifier(**xgbParams, featuresCol=\"features\", labelCol=\"VAR_OBJETIVO\", validationIndicatorCol='isVal', early_stopping_rounds=50, predictionCol=\"prediction\",\n                        probabilityCol=\"probability\", eval_metric=[\"mlogloss\"])\n    )\n    model = xgb.fit(train_sdf_prepared)\n    \n    mlflow.log_param(\"hyper-parameters\", xgbParams)\n    mlflow.log_param(\"max_depth\", xgbParams[\"max_depth\"])\n    mlflow.log_param(\"eta\", xgbParams[\"eta\"])\n    mlflow.log_param(\"reg_alpha\", xgbParams[\"reg_alpha\"])\n    mlflow.log_param(\"reg_lambda\", xgbParams[\"reg_lambda\"])\n    mlflow.log_param(\"min_child_weight\", xgbParams[\"min_child_weight\"])\n    mlflow.log_param(\"subsample\", xgbParams[\"subsample\"])\n    \n    print(\"Start predict\")\n    result = model.transform(test_sdf_prepared)\n    result_pd = result.select(\"VAR_OBJETIVO\", \"prediction\").toPandas()\n    result_pd.to_csv(\"results.csv\", index=False, sep=\"|\")\n    mlflow.log_artifact(\"results.csv\")\n    \n    print(\"Start metrics\")\n    target_names = [\"falsa\", \"sindefinir_fallida\", \"verdadera_nopard\", \"verdadera_pard_noinst\", \"verdadera_pard_inst\"]\n    print_classif = classification_report(result_pd[\"VAR_OBJETIVO\"], result_pd[\"prediction\"], output_dict=True,target_names=target_names)\n    acc = print_classif[\"accuracy\"]\n    print(acc)\n    metrics = dict(avg_recall = print_classif[\"macro avg\"][\"recall\"], avg_f1score = print_classif[\"macro avg\"][\"f1-score\"], \n                   acc = print_classif[\"accuracy\"], falsa_recall = print_classif[\"falsa\"][\"recall\"],\n                   sindef_recall = print_classif[\"sindefinir_fallida\"][\"recall\"], verdnopard_recall = print_classif[\"verdadera_nopard\"][\"recall\"],\n                   pardnoinst_recall = print_classif[\"verdadera_pard_noinst\"][\"recall\"], pardinst_recall = print_classif[\"verdadera_pard_inst\"][\"recall\"],\n                   falsa_f1score = print_classif[\"falsa\"][\"f1-score\"], sindef_f1score = print_classif[\"sindefinir_fallida\"][\"f1-score\"], \n                   verdnopard_f1score = print_classif[\"verdadera_nopard\"][\"f1-score\"], pardnoinst_f1score = print_classif[\"verdadera_pard_noinst\"][\"f1-score\"],\n                   pardinst_f1score = print_classif[\"verdadera_pard_inst\"][\"f1-score\"]\n                  )\n    mlflow.log_metrics(metrics)\n    \n    mlflow.spark.log_model(model, \"model\")\n    \n    return {'status': STATUS_OK, 'loss': -1*acc}\n  \nspark_trials = Trials()\n\nwith mlflow.start_run(run_name='xgboost_noweights'):\n  best_params = fmin(\n    fn=train_model, \n    space=search_space, \n    algo=tpe.suggest, \n    max_evals=50,\n    trials=spark_trials, \n    rstate=np.random.RandomState(5)\n  )\nprint(best_params)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9893d52-6059-4d3e-afc7-583f28cb9f5c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\r  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]\r                                                      \rStart training\n\r  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]\r                                                      \rStart predict\n\r  0%|          | 0/50 [18:01&lt;?, ?trial/s, best loss=?]\r                                                      \rStart metrics\n\r  0%|          | 0/50 [18:28&lt;?, ?trial/s, best loss=?]\r                                                      \r0.14784798534798535\n\r  0%|          | 0/50 [18:29&lt;?, ?trial/s, best loss=?]\r  2%|▏         | 1/50 [18:38&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \rStart training\n\r  2%|▏         | 1/50 [18:38&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \rStart predict\n\r  2%|▏         | 1/50 [22:48&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \rStart metrics\n\r  2%|▏         | 1/50 [22:57&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \r0.10542328042328042\n\r  2%|▏         | 1/50 [22:57&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r  4%|▍         | 2/50 [23:01&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]  \r                                                                                     \rStart training\n\r  4%|▍         | 2/50 [23:01&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r                                                                                     \rStart predict\n\r  4%|▍         | 2/50 [26:31&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r                                                                                     \rStart metrics\n\r  4%|▍         | 2/50 [26:39&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r                                                                                     \r0.29622507122507125\n\r  4%|▍         | 2/50 [26:39&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r  6%|▌         | 3/50 [26:43&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart training\n\r  6%|▌         | 3/50 [26:44&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart predict\n\r  6%|▌         | 3/50 [32:59&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart metrics\n\r  6%|▌         | 3/50 [33:11&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \r0.10573870573870574\n\r  6%|▌         | 3/50 [33:12&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r  8%|▊         | 4/50 [33:16&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart training\n\r  8%|▊         | 4/50 [33:16&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart predict\n\r  8%|▊         | 4/50 [50:00&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart metrics\n\r  8%|▊         | 4/50 [50:21&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \r0.0862077737077737\n\r  8%|▊         | 4/50 [50:22&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r 10%|█         | 5/50 [50:31&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart training\n\r 10%|█         | 5/50 [50:31&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart predict\n\r 10%|█         | 5/50 [1:05:30&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart metrics\n\r 10%|█         | 5/50 [1:05:48&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                       \r0.10595746845746845\n\r 10%|█         | 5/50 [1:05:48&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r 12%|█▏        | 6/50 [1:05:55&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart training\n\r 12%|█▏        | 6/50 [1:05:56&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart predict\n\r 12%|█▏        | 6/50 [2:36:04&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart metrics\n\r 12%|█▏        | 6/50 [2:37:44&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \r0.20714794464794464\n\r 12%|█▏        | 6/50 [2:37:44&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r 14%|█▍        | 7/50 [2:38:04&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 14%|█▍        | 7/50 [2:38:04&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 14%|█▍        | 7/50 [2:47:45&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 14%|█▍        | 7/50 [2:48:05&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.0796906796906797\n\r 14%|█▍        | 7/50 [2:48:06&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r 16%|█▌        | 8/50 [2:48:10&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 16%|█▌        | 8/50 [2:48:11&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 16%|█▌        | 8/50 [3:42:58&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 16%|█▌        | 8/50 [3:43:48&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.08680301180301181\n\r 16%|█▌        | 8/50 [3:43:49&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r 18%|█▊        | 9/50 [3:43:58&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 18%|█▊        | 9/50 [3:43:59&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 18%|█▊        | 9/50 [3:50:49&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.0643009768009768\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r 20%|██        | 10/50 [3:51:11&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 20%|██        | 10/50 [3:51:11&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 20%|██        | 10/50 [4:07:21&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 20%|██        | 10/50 [4:07:46&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.09052706552706553\n\r 20%|██        | 10/50 [4:07:46&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r 22%|██▏       | 11/50 [4:07:52&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 22%|██▏       | 11/50 [4:07:53&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 22%|██▏       | 11/50 [4:12:21&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.11187932437932438\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r 24%|██▍       | 12/50 [4:12:40&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 24%|██▍       | 12/50 [4:12:40&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 24%|██▍       | 12/50 [4:15:24&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 24%|██▍       | 12/50 [4:15:38&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.23354192104192104\n\r 24%|██▍       | 12/50 [4:15:39&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r 26%|██▌       | 13/50 [4:16:04&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]  \r                                                                                        \rStart training\n\r 26%|██▌       | 13/50 [4:16:04&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 26%|██▌       | 13/50 [4:36:23&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 26%|██▌       | 13/50 [4:36:56&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.14982702482702484\n\r 26%|██▌       | 13/50 [4:36:57&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r 28%|██▊       | 14/50 [4:37:24&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 28%|██▊       | 14/50 [4:37:25&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 28%|██▊       | 14/50 [4:40:33&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 28%|██▊       | 14/50 [4:40:47&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.07850529100529101\n\r 28%|██▊       | 14/50 [4:40:47&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r 30%|███       | 15/50 [4:40:51&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 30%|███       | 15/50 [4:40:51&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 30%|███       | 15/50 [4:47:49&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 30%|███       | 15/50 [4:48:08&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.06553215303215303\n\r 30%|███       | 15/50 [4:48:08&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r 32%|███▏      | 16/50 [4:48:12&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 32%|███▏      | 16/50 [4:48:13&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 32%|███▏      | 16/50 [5:03:53&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 32%|███▏      | 16/50 [5:04:19&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.09774623524623524\n\r 32%|███▏      | 16/50 [5:04:20&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r 34%|███▍      | 17/50 [5:04:25&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 34%|███▍      | 17/50 [5:04:25&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 34%|███▍      | 17/50 [5:31:45&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 34%|███▍      | 17/50 [5:32:25&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.15186202686202685\n\r 34%|███▍      | 17/50 [5:32:26&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r 36%|███▌      | 18/50 [5:32:36&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 36%|███▌      | 18/50 [5:32:36&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 36%|███▌      | 18/50 [6:02:17&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 36%|███▌      | 18/50 [6:02:54&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.10816544566544567\n\r 36%|███▌      | 18/50 [6:02:55&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r 38%|███▊      | 19/50 [6:03:02&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 38%|███▊      | 19/50 [6:03:02&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 38%|███▊      | 19/50 [6:24:01&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 38%|███▊      | 19/50 [6:24:32&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.12500508750508751\n\r 38%|███▊      | 19/50 [6:24:32&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r 40%|████      | 20/50 [6:24:39&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 40%|████      | 20/50 [6:24:39&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 40%|████      | 20/50 [6:27:41&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 40%|████      | 20/50 [6:27:57&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.13552096052096052\n\r 40%|████      | 20/50 [6:27:57&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r 42%|████▏     | 21/50 [6:28:03&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]  \r                                                                                        \rStart training\n\r 42%|████▏     | 21/50 [6:28:03&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 42%|████▏     | 21/50 [6:31:08&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 42%|████▏     | 21/50 [6:31:23&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.25157712657712655\n\r 42%|████▏     | 21/50 [6:31:23&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r 44%|████▍     | 22/50 [6:31:27&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 44%|████▍     | 22/50 [6:31:27&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 44%|████▍     | 22/50 [6:36:25&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 44%|████▍     | 22/50 [6:36:41&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.16508954008954008\n\r 44%|████▍     | 22/50 [6:36:41&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r 46%|████▌     | 23/50 [6:36:45&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 46%|████▌     | 23/50 [6:36:45&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 46%|████▌     | 23/50 [6:40:46&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 46%|████▌     | 23/50 [6:41:03&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.19605209605209606\n\r 46%|████▌     | 23/50 [6:41:03&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r 48%|████▊     | 24/50 [6:41:06&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 48%|████▊     | 24/50 [6:41:07&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 48%|████▊     | 24/50 [6:46:26&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 48%|████▊     | 24/50 [6:46:42&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.13574989824989825\n\r 48%|████▊     | 24/50 [6:46:42&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r 50%|█████     | 25/50 [6:46:46&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 50%|█████     | 25/50 [6:46:46&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 50%|█████     | 25/50 [6:49:55&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 50%|█████     | 25/50 [6:50:09&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.29176841676841675\n\r 50%|█████     | 25/50 [6:50:10&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r 52%|█████▏    | 26/50 [6:50:13&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 52%|█████▏    | 26/50 [6:50:13&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 52%|█████▏    | 26/50 [6:55:17&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 52%|█████▏    | 26/50 [6:55:33&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.15107346357346357\n\r 52%|█████▏    | 26/50 [6:55:33&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r 54%|█████▍    | 27/50 [6:55:37&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 54%|█████▍    | 27/50 [6:55:37&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 54%|█████▍    | 27/50 [7:02:35&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 54%|█████▍    | 27/50 [7:02:52&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.10112942612942613\n\r 54%|█████▍    | 27/50 [7:02:52&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r 56%|█████▌    | 28/50 [7:02:56&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 56%|█████▌    | 28/50 [7:02:56&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 56%|█████▌    | 28/50 [7:06:37&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 56%|█████▌    | 28/50 [7:06:52&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.0707977207977208\n\r 56%|█████▌    | 28/50 [7:06:52&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r 58%|█████▊    | 29/50 [7:06:55&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 58%|█████▊    | 29/50 [7:06:56&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 58%|█████▊    | 29/50 [7:09:41&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 58%|█████▊    | 29/50 [7:09:56&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.28501221001221\n\r 58%|█████▊    | 29/50 [7:09:56&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r 60%|██████    | 30/50 [7:10:00&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 60%|██████    | 30/50 [7:10:01&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 60%|██████    | 30/50 [7:20:19&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 60%|██████    | 30/50 [7:20:39&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.06658017908017907\n\r 60%|██████    | 30/50 [7:20:39&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r 62%|██████▏   | 31/50 [7:20:43&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 62%|██████▏   | 31/50 [7:20:44&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 62%|██████▏   | 31/50 [7:26:02&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 62%|██████▏   | 31/50 [7:26:18&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.09208892958892959\n\r 62%|██████▏   | 31/50 [7:26:18&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r 64%|██████▍   | 32/50 [7:26:22&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 64%|██████▍   | 32/50 [7:26:22&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 64%|██████▍   | 32/50 [8:29:44&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 64%|██████▍   | 32/50 [8:30:35&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.10235042735042735\n\r 64%|██████▍   | 32/50 [8:30:35&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r 66%|██████▌   | 33/50 [8:30:47&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 66%|██████▌   | 33/50 [8:30:47&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 66%|██████▌   | 33/50 [8:37:53&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 66%|██████▌   | 33/50 [8:38:10&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.0737891737891738\n\r 66%|██████▌   | 33/50 [8:38:10&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r 68%|██████▊   | 34/50 [8:38:15&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 68%|██████▊   | 34/50 [8:38:15&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 68%|██████▊   | 34/50 [8:42:02&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 68%|██████▊   | 34/50 [8:42:17&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.08855311355311356\n\r 68%|██████▊   | 34/50 [8:42:17&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r 70%|███████   | 35/50 [8:42:21&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125] \r                                                                                        \rStart training\n\r 70%|███████   | 35/50 [8:42:21&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 70%|███████   | 35/50 [9:02:27&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 70%|███████   | 35/50 [9:02:54&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.11703296703296703\n\r 70%|███████   | 35/50 [9:02:54&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r 72%|███████▏  | 36/50 [9:03:00&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 72%|███████▏  | 36/50 [9:03:00&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 72%|███████▏  | 36/50 [9:06:29&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 72%|███████▏  | 36/50 [9:06:46&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.23794770044770044\n\r 72%|███████▏  | 36/50 [9:06:47&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r 74%|███████▍  | 37/50 [9:06:50&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 74%|███████▍  | 37/50 [9:06:51&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 74%|███████▍  | 37/50 [9:14:52&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 74%|███████▍  | 37/50 [9:15:10&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.07256308506308506\n\r 74%|███████▍  | 37/50 [9:15:10&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r 76%|███████▌  | 38/50 [9:15:14&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 76%|███████▌  | 38/50 [9:15:15&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 76%|███████▌  | 38/50 [9:21:29&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 76%|███████▌  | 38/50 [9:21:46&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.09231786731786731\n\r 76%|███████▌  | 38/50 [9:21:46&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r 78%|███████▊  | 39/50 [9:21:50&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 78%|███████▊  | 39/50 [9:21:51&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 78%|███████▊  | 39/50 [9:52:24&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 78%|███████▊  | 39/50 [9:52:58&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.30027472527472526\n\r 78%|███████▊  | 39/50 [9:52:59&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r 80%|████████  | 40/50 [9:53:08&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart training\n\r 80%|████████  | 40/50 [9:53:09&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart predict\n\r 80%|████████  | 40/50 [12:01:53&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                         \rStart metrics\n\r 80%|████████  | 40/50 [12:03:33&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                         \r0.11072446072446072\n\r 80%|████████  | 40/50 [12:03:34&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r 82%|████████▏ | 41/50 [12:03:55&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 82%|████████▏ | 41/50 [12:03:55&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 82%|████████▏ | 41/50 [12:59:34&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 82%|████████▏ | 41/50 [13:00:33&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.14521774521774522\n\r 82%|████████▏ | 41/50 [13:00:34&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r 84%|████████▍ | 42/50 [13:00:45&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 84%|████████▍ | 42/50 [13:00:46&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 84%|████████▍ | 42/50 [14:04:22&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 84%|████████▍ | 42/50 [14:05:16&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.2226800976800977\n\r 84%|████████▍ | 42/50 [14:05:16&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r 86%|████████▌ | 43/50 [14:05:27&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 86%|████████▌ | 43/50 [14:05:27&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 86%|████████▌ | 43/50 [14:45:48&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 86%|████████▌ | 43/50 [14:46:29&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.12736060236060237\n\r 86%|████████▌ | 43/50 [14:46:29&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r 88%|████████▊ | 44/50 [14:46:37&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 88%|████████▊ | 44/50 [14:46:37&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 88%|████████▊ | 44/50 [15:42:05&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 88%|████████▊ | 44/50 [15:42:52&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.18087098087098086\n\r 88%|████████▊ | 44/50 [15:42:53&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r 90%|█████████ | 45/50 [15:43:02&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 90%|█████████ | 45/50 [15:43:02&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 90%|█████████ | 45/50 [16:01:57&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 90%|█████████ | 45/50 [16:02:23&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.09552808302808302\n\r 90%|█████████ | 45/50 [16:02:23&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r 92%|█████████▏| 46/50 [16:02:30&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 92%|█████████▏| 46/50 [16:02:30&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 92%|█████████▏| 46/50 [17:20:08&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 92%|█████████▏| 46/50 [17:21:12&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.10688339438339438\n\r 92%|█████████▏| 46/50 [17:21:13&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r 94%|█████████▍| 47/50 [17:21:25&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 94%|█████████▍| 47/50 [17:21:25&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 94%|█████████▍| 47/50 [17:34:40&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 94%|█████████▍| 47/50 [17:35:04&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.08167480667480667\n\r 94%|█████████▍| 47/50 [17:35:05&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r 96%|█████████▌| 48/50 [17:35:10&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 96%|█████████▌| 48/50 [17:35:10&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 96%|█████████▌| 48/50 [17:58:54&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 96%|█████████▌| 48/50 [17:59:24&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.10863349613349613\n\r 96%|█████████▌| 48/50 [17:59:25&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r 98%|█████████▊| 49/50 [17:59:35&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]  \r                                                                                        \rStart training\n\r 98%|█████████▊| 49/50 [17:59:36&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart predict\n\r 98%|█████████▊| 49/50 [18:23:49&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart metrics\n\r 98%|█████████▊| 49/50 [18:24:21&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r                                                                                        \r0.13096255596255596\n\r 98%|█████████▊| 49/50 [18:24:22&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r100%|██████████| 50/50 [18:24:54&lt;00:00, 1991.42s/trial, best loss: -0.30027472527472526]\r100%|██████████| 50/50 [18:24:54&lt;00:00, 1325.89s/trial, best loss: -0.30027472527472526]\n{&#39;eta&#39;: 0.38848266999015246, &#39;max_depth&#39;: 13.0, &#39;min_child_weight&#39;: 20.08262293050307, &#39;reg_alpha&#39;: 0.42268704090105524, &#39;reg_lambda&#39;: 0.7640847142362472, &#39;subsample&#39;: 0.9458624395316312}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]\r                                                      \rStart training\n\r  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]\r                                                      \rStart predict\n\r  0%|          | 0/50 [18:01&lt;?, ?trial/s, best loss=?]\r                                                      \rStart metrics\n\r  0%|          | 0/50 [18:28&lt;?, ?trial/s, best loss=?]\r                                                      \r0.14784798534798535\n\r  0%|          | 0/50 [18:29&lt;?, ?trial/s, best loss=?]\r  2%|▏         | 1/50 [18:38&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \rStart training\n\r  2%|▏         | 1/50 [18:38&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \rStart predict\n\r  2%|▏         | 1/50 [22:48&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \rStart metrics\n\r  2%|▏         | 1/50 [22:57&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r                                                                                       \r0.10542328042328042\n\r  2%|▏         | 1/50 [22:57&lt;15:13:04, 1118.06s/trial, best loss: -0.14784798534798535]\r  4%|▍         | 2/50 [23:01&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]  \r                                                                                     \rStart training\n\r  4%|▍         | 2/50 [23:01&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r                                                                                     \rStart predict\n\r  4%|▍         | 2/50 [26:31&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r                                                                                     \rStart metrics\n\r  4%|▍         | 2/50 [26:39&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r                                                                                     \r0.29622507122507125\n\r  4%|▍         | 2/50 [26:39&lt;8:12:16, 615.35s/trial, best loss: -0.14784798534798535]\r  6%|▌         | 3/50 [26:43&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart training\n\r  6%|▌         | 3/50 [26:44&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart predict\n\r  6%|▌         | 3/50 [32:59&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart metrics\n\r  6%|▌         | 3/50 [33:11&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r                                                                                     \r0.10573870573870574\n\r  6%|▌         | 3/50 [33:12&lt;5:41:25, 435.86s/trial, best loss: -0.29622507122507125]\r  8%|▊         | 4/50 [33:16&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart training\n\r  8%|▊         | 4/50 [33:16&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart predict\n\r  8%|▊         | 4/50 [50:00&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart metrics\n\r  8%|▊         | 4/50 [50:21&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r                                                                                     \r0.0862077737077737\n\r  8%|▊         | 4/50 [50:22&lt;5:21:09, 418.90s/trial, best loss: -0.29622507122507125]\r 10%|█         | 5/50 [50:31&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart training\n\r 10%|█         | 5/50 [50:31&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                     \rStart predict\n\r 10%|█         | 5/50 [1:05:30&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart metrics\n\r 10%|█         | 5/50 [1:05:48&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r                                                                                       \r0.10595746845746845\n\r 10%|█         | 5/50 [1:05:48&lt;8:00:47, 641.06s/trial, best loss: -0.29622507122507125]\r 12%|█▏        | 6/50 [1:05:55&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart training\n\r 12%|█▏        | 6/50 [1:05:56&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart predict\n\r 12%|█▏        | 6/50 [2:36:04&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \rStart metrics\n\r 12%|█▏        | 6/50 [2:37:44&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r                                                                                       \r0.20714794464794464\n\r 12%|█▏        | 6/50 [2:37:44&lt;9:00:44, 737.38s/trial, best loss: -0.29622507122507125]\r 14%|█▍        | 7/50 [2:38:04&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 14%|█▍        | 7/50 [2:38:04&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 14%|█▍        | 7/50 [2:47:45&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 14%|█▍        | 7/50 [2:48:05&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.0796906796906797\n\r 14%|█▍        | 7/50 [2:48:06&lt;27:30:54, 2303.60s/trial, best loss: -0.29622507122507125]\r 16%|█▌        | 8/50 [2:48:10&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 16%|█▌        | 8/50 [2:48:11&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 16%|█▌        | 8/50 [3:42:58&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 16%|█▌        | 8/50 [3:43:48&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.08680301180301181\n\r 16%|█▌        | 8/50 [3:43:49&lt;20:34:22, 1763.40s/trial, best loss: -0.29622507122507125]\r 18%|█▊        | 9/50 [3:43:58&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 18%|█▊        | 9/50 [3:43:59&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 18%|█▊        | 9/50 [3:50:49&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.0643009768009768\n\r 18%|█▊        | 9/50 [3:51:06&lt;25:43:26, 2258.70s/trial, best loss: -0.29622507122507125]\r 20%|██        | 10/50 [3:51:11&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 20%|██        | 10/50 [3:51:11&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 20%|██        | 10/50 [4:07:21&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 20%|██        | 10/50 [4:07:46&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.09052706552706553\n\r 20%|██        | 10/50 [4:07:46&lt;18:49:55, 1694.88s/trial, best loss: -0.29622507122507125]\r 22%|██▏       | 11/50 [4:07:52&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 22%|██▏       | 11/50 [4:07:53&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 22%|██▏       | 11/50 [4:12:21&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r/databricks/python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.11187932437932438\n\r 22%|██▏       | 11/50 [4:12:36&lt;16:03:45, 1482.72s/trial, best loss: -0.29622507122507125]\r 24%|██▍       | 12/50 [4:12:40&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 24%|██▍       | 12/50 [4:12:40&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 24%|██▍       | 12/50 [4:15:24&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 24%|██▍       | 12/50 [4:15:38&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.23354192104192104\n\r 24%|██▍       | 12/50 [4:15:39&lt;11:48:47, 1119.14s/trial, best loss: -0.29622507122507125]\r 26%|██▌       | 13/50 [4:16:04&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]  \r                                                                                        \rStart training\n\r 26%|██▌       | 13/50 [4:16:04&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 26%|██▌       | 13/50 [4:36:23&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 26%|██▌       | 13/50 [4:36:56&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.14982702482702484\n\r 26%|██▌       | 13/50 [4:36:57&lt;8:39:07, 841.83s/trial, best loss: -0.29622507122507125]\r 28%|██▊       | 14/50 [4:37:24&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 28%|██▊       | 14/50 [4:37:25&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 28%|██▊       | 14/50 [4:40:33&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 28%|██▊       | 14/50 [4:40:47&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.07850529100529101\n\r 28%|██▊       | 14/50 [4:40:47&lt;9:44:40, 974.46s/trial, best loss: -0.29622507122507125]\r 30%|███       | 15/50 [4:40:51&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 30%|███       | 15/50 [4:40:51&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 30%|███       | 15/50 [4:47:49&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 30%|███       | 15/50 [4:48:08&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.06553215303215303\n\r 30%|███       | 15/50 [4:48:08&lt;7:13:22, 742.92s/trial, best loss: -0.29622507122507125]\r 32%|███▏      | 16/50 [4:48:12&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 32%|███▏      | 16/50 [4:48:13&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 32%|███▏      | 16/50 [5:03:53&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 32%|███▏      | 16/50 [5:04:19&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.09774623524623524\n\r 32%|███▏      | 16/50 [5:04:20&lt;6:09:36, 652.26s/trial, best loss: -0.29622507122507125]\r 34%|███▍      | 17/50 [5:04:25&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 34%|███▍      | 17/50 [5:04:25&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 34%|███▍      | 17/50 [5:31:45&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 34%|███▍      | 17/50 [5:32:25&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.15186202686202685\n\r 34%|███▍      | 17/50 [5:32:26&lt;6:51:40, 748.51s/trial, best loss: -0.29622507122507125]\r 36%|███▌      | 18/50 [5:32:36&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 36%|███▌      | 18/50 [5:32:36&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 36%|███▌      | 18/50 [6:02:17&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 36%|███▌      | 18/50 [6:02:54&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.10816544566544567\n\r 36%|███▌      | 18/50 [6:02:55&lt;9:10:13, 1031.66s/trial, best loss: -0.29622507122507125]\r 38%|███▊      | 19/50 [6:03:02&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 38%|███▊      | 19/50 [6:03:02&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 38%|███▊      | 19/50 [6:24:01&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 38%|███▊      | 19/50 [6:24:32&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.12500508750508751\n\r 38%|███▊      | 19/50 [6:24:32&lt;10:56:21, 1270.37s/trial, best loss: -0.29622507122507125]\r 40%|████      | 20/50 [6:24:39&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart training\n\r 40%|████      | 20/50 [6:24:39&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart predict\n\r 40%|████      | 20/50 [6:27:41&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \rStart metrics\n\r 40%|████      | 20/50 [6:27:57&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r                                                                                          \r0.13552096052096052\n\r 40%|████      | 20/50 [6:27:57&lt;10:39:07, 1278.24s/trial, best loss: -0.29622507122507125]\r 42%|████▏     | 21/50 [6:28:03&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]  \r                                                                                        \rStart training\n\r 42%|████▏     | 21/50 [6:28:03&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 42%|████▏     | 21/50 [6:31:08&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 42%|████▏     | 21/50 [6:31:23&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.25157712657712655\n\r 42%|████▏     | 21/50 [6:31:23&lt;7:41:58, 955.82s/trial, best loss: -0.29622507122507125]\r 44%|████▍     | 22/50 [6:31:27&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 44%|████▍     | 22/50 [6:31:27&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 44%|████▍     | 22/50 [6:36:25&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 44%|████▍     | 22/50 [6:36:41&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.16508954008954008\n\r 44%|████▍     | 22/50 [6:36:41&lt;5:40:43, 730.13s/trial, best loss: -0.29622507122507125]\r 46%|████▌     | 23/50 [6:36:45&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 46%|████▌     | 23/50 [6:36:45&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 46%|████▌     | 23/50 [6:40:46&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 46%|████▌     | 23/50 [6:41:03&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.19605209605209606\n\r 46%|████▌     | 23/50 [6:41:03&lt;4:32:54, 606.47s/trial, best loss: -0.29622507122507125]\r 48%|████▊     | 24/50 [6:41:06&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 48%|████▊     | 24/50 [6:41:07&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 48%|████▊     | 24/50 [6:46:26&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 48%|████▊     | 24/50 [6:46:42&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.13574989824989825\n\r 48%|████▊     | 24/50 [6:46:42&lt;3:37:57, 502.99s/trial, best loss: -0.29622507122507125]\r 50%|█████     | 25/50 [6:46:46&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 50%|█████     | 25/50 [6:46:46&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 50%|█████     | 25/50 [6:49:55&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 50%|█████     | 25/50 [6:50:09&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.29176841676841675\n\r 50%|█████     | 25/50 [6:50:10&lt;3:09:07, 453.90s/trial, best loss: -0.29622507122507125]\r 52%|█████▏    | 26/50 [6:50:13&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 52%|█████▏    | 26/50 [6:50:13&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 52%|█████▏    | 26/50 [6:55:17&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 52%|█████▏    | 26/50 [6:55:33&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.15107346357346357\n\r 52%|█████▏    | 26/50 [6:55:33&lt;2:31:58, 379.93s/trial, best loss: -0.29622507122507125]\r 54%|█████▍    | 27/50 [6:55:37&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 54%|█████▍    | 27/50 [6:55:37&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 54%|█████▍    | 27/50 [7:02:35&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 54%|█████▍    | 27/50 [7:02:52&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.10112942612942613\n\r 54%|█████▍    | 27/50 [7:02:52&lt;2:19:11, 363.11s/trial, best loss: -0.29622507122507125]\r 56%|█████▌    | 28/50 [7:02:56&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 56%|█████▌    | 28/50 [7:02:56&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 56%|█████▌    | 28/50 [7:06:37&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 56%|█████▌    | 28/50 [7:06:52&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.0707977207977208\n\r 56%|█████▌    | 28/50 [7:06:52&lt;2:21:29, 385.89s/trial, best loss: -0.29622507122507125]\r 58%|█████▊    | 29/50 [7:06:55&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 58%|█████▊    | 29/50 [7:06:56&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 58%|█████▊    | 29/50 [7:09:41&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 58%|█████▊    | 29/50 [7:09:56&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.28501221001221\n\r 58%|█████▊    | 29/50 [7:09:56&lt;1:59:41, 341.98s/trial, best loss: -0.29622507122507125]\r 60%|██████    | 30/50 [7:10:00&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 60%|██████    | 30/50 [7:10:01&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 60%|██████    | 30/50 [7:20:19&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 60%|██████    | 30/50 [7:20:39&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.06658017908017907\n\r 60%|██████    | 30/50 [7:20:39&lt;1:38:16, 294.81s/trial, best loss: -0.29622507122507125]\r 62%|██████▏   | 31/50 [7:20:43&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 62%|██████▏   | 31/50 [7:20:44&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 62%|██████▏   | 31/50 [7:26:02&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 62%|██████▏   | 31/50 [7:26:18&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.09208892958892959\n\r 62%|██████▏   | 31/50 [7:26:18&lt;2:06:26, 399.28s/trial, best loss: -0.29622507122507125]\r 64%|██████▍   | 32/50 [7:26:22&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 64%|██████▍   | 32/50 [7:26:22&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 64%|██████▍   | 32/50 [8:29:44&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 64%|██████▍   | 32/50 [8:30:35&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.10235042735042735\n\r 64%|██████▍   | 32/50 [8:30:35&lt;1:54:17, 380.98s/trial, best loss: -0.29622507122507125]\r 66%|██████▌   | 33/50 [8:30:47&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 66%|██████▌   | 33/50 [8:30:47&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 66%|██████▌   | 33/50 [8:37:53&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 66%|██████▌   | 33/50 [8:38:10&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.0737891737891738\n\r 66%|██████▌   | 33/50 [8:38:10&lt;6:44:07, 1426.30s/trial, best loss: -0.29622507122507125]\r 68%|██████▊   | 34/50 [8:38:15&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart training\n\r 68%|██████▊   | 34/50 [8:38:15&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart predict\n\r 68%|██████▊   | 34/50 [8:42:02&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \rStart metrics\n\r 68%|██████▊   | 34/50 [8:42:17&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r                                                                                         \r0.08855311355311356\n\r 68%|██████▊   | 34/50 [8:42:17&lt;5:02:05, 1132.87s/trial, best loss: -0.29622507122507125]\r 70%|███████   | 35/50 [8:42:21&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125] \r                                                                                        \rStart training\n\r 70%|███████   | 35/50 [8:42:21&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 70%|███████   | 35/50 [9:02:27&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 70%|███████   | 35/50 [9:02:54&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.11703296703296703\n\r 70%|███████   | 35/50 [9:02:54&lt;3:36:39, 866.66s/trial, best loss: -0.29622507122507125]\r 72%|███████▏  | 36/50 [9:03:00&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 72%|███████▏  | 36/50 [9:03:00&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 72%|███████▏  | 36/50 [9:06:29&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 72%|███████▏  | 36/50 [9:06:46&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.23794770044770044\n\r 72%|███████▏  | 36/50 [9:06:47&lt;3:48:17, 978.39s/trial, best loss: -0.29622507122507125]\r 74%|███████▍  | 37/50 [9:06:50&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 74%|███████▍  | 37/50 [9:06:51&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 74%|███████▍  | 37/50 [9:14:52&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 74%|███████▍  | 37/50 [9:15:10&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.07256308506308506\n\r 74%|███████▍  | 37/50 [9:15:10&lt;2:43:22, 754.04s/trial, best loss: -0.29622507122507125]\r 76%|███████▌  | 38/50 [9:15:14&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 76%|███████▌  | 38/50 [9:15:15&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 76%|███████▌  | 38/50 [9:21:29&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 76%|███████▌  | 38/50 [9:21:46&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.09231786731786731\n\r 76%|███████▌  | 38/50 [9:21:46&lt;2:15:48, 679.08s/trial, best loss: -0.29622507122507125]\r 78%|███████▊  | 39/50 [9:21:50&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart training\n\r 78%|███████▊  | 39/50 [9:21:51&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart predict\n\r 78%|███████▊  | 39/50 [9:52:24&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \rStart metrics\n\r 78%|███████▊  | 39/50 [9:52:58&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r                                                                                        \r0.30027472527472526\n\r 78%|███████▊  | 39/50 [9:52:59&lt;1:48:55, 594.16s/trial, best loss: -0.29622507122507125]\r 80%|████████  | 40/50 [9:53:08&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart training\n\r 80%|████████  | 40/50 [9:53:09&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart predict\n\r 80%|████████  | 40/50 [12:01:53&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                         \rStart metrics\n\r 80%|████████  | 40/50 [12:03:33&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r                                                                                         \r0.11072446072446072\n\r 80%|████████  | 40/50 [12:03:34&lt;2:43:13, 979.34s/trial, best loss: -0.30027472527472526]\r 82%|████████▏ | 41/50 [12:03:55&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 82%|████████▏ | 41/50 [12:03:55&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 82%|████████▏ | 41/50 [12:59:34&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 82%|████████▏ | 41/50 [13:00:33&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.14521774521774522\n\r 82%|████████▏ | 41/50 [13:00:34&lt;7:35:54, 3039.43s/trial, best loss: -0.30027472527472526]\r 84%|████████▍ | 42/50 [13:00:45&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 84%|████████▍ | 42/50 [13:00:46&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 84%|████████▍ | 42/50 [14:04:22&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 84%|████████▍ | 42/50 [14:05:16&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.2226800976800977\n\r 84%|████████▍ | 42/50 [14:05:16&lt;7:00:06, 3150.80s/trial, best loss: -0.30027472527472526]\r 86%|████████▌ | 43/50 [14:05:27&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 86%|████████▌ | 43/50 [14:05:27&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 86%|████████▌ | 43/50 [14:45:48&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 86%|████████▌ | 43/50 [14:46:29&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.12736060236060237\n\r 86%|████████▌ | 43/50 [14:46:29&lt;6:33:09, 3369.96s/trial, best loss: -0.30027472527472526]\r 88%|████████▊ | 44/50 [14:46:37&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 88%|████████▊ | 44/50 [14:46:37&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 88%|████████▊ | 44/50 [15:42:05&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 88%|████████▊ | 44/50 [15:42:52&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.18087098087098086\n\r 88%|████████▊ | 44/50 [15:42:53&lt;5:09:59, 3099.93s/trial, best loss: -0.30027472527472526]\r 90%|█████████ | 45/50 [15:43:02&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 90%|█████████ | 45/50 [15:43:02&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 90%|█████████ | 45/50 [16:01:57&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 90%|█████████ | 45/50 [16:02:23&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.09552808302808302\n\r 90%|█████████ | 45/50 [16:02:23&lt;4:25:27, 3185.49s/trial, best loss: -0.30027472527472526]\r 92%|█████████▏| 46/50 [16:02:30&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 92%|█████████▏| 46/50 [16:02:30&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 92%|█████████▏| 46/50 [17:20:08&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 92%|█████████▏| 46/50 [17:21:12&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.10688339438339438\n\r 92%|█████████▏| 46/50 [17:21:13&lt;2:52:01, 2580.29s/trial, best loss: -0.30027472527472526]\r 94%|█████████▍| 47/50 [17:21:25&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 94%|█████████▍| 47/50 [17:21:25&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 94%|█████████▍| 47/50 [17:34:40&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 94%|█████████▍| 47/50 [17:35:04&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.08167480667480667\n\r 94%|█████████▍| 47/50 [17:35:05&lt;2:41:20, 3226.74s/trial, best loss: -0.30027472527472526]\r 96%|█████████▌| 48/50 [17:35:10&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart training\n\r 96%|█████████▌| 48/50 [17:35:10&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart predict\n\r 96%|█████████▌| 48/50 [17:58:54&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \rStart metrics\n\r 96%|█████████▌| 48/50 [17:59:24&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r                                                                                          \r0.10863349613349613\n\r 96%|█████████▌| 48/50 [17:59:25&lt;1:23:32, 2506.16s/trial, best loss: -0.30027472527472526]\r 98%|█████████▊| 49/50 [17:59:35&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]  \r                                                                                        \rStart training\n\r 98%|█████████▊| 49/50 [17:59:36&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart predict\n\r 98%|█████████▊| 49/50 [18:23:49&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r                                                                                        \rStart metrics\n\r 98%|█████████▊| 49/50 [18:24:21&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r                                                                                        \r0.13096255596255596\n\r 98%|█████████▊| 49/50 [18:24:22&lt;36:33, 2193.89s/trial, best loss: -0.30027472527472526]\r100%|██████████| 50/50 [18:24:54&lt;00:00, 1991.42s/trial, best loss: -0.30027472527472526]\r100%|██████████| 50/50 [18:24:54&lt;00:00, 1325.89s/trial, best loss: -0.30027472527472526]\n{&#39;eta&#39;: 0.38848266999015246, &#39;max_depth&#39;: 13.0, &#39;min_child_weight&#39;: 20.08262293050307, &#39;reg_alpha&#39;: 0.42268704090105524, &#39;reg_lambda&#39;: 0.7640847142362472, &#39;subsample&#39;: 0.9458624395316312}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Se carga desde MLflow el mejor entrenamiento y su ID\nbest_run = mlflow.search_runs(experiment_ids=1528115081293925, filter_string=\"tags.mlflow.databricks.notebookPath LIKE '%final_python_denuncias_noweights'\", order_by=['metrics.acc DESC']).iloc[0]\nprint(f'Accuracy del mejor modelo: {best_run[\"metrics.acc\"]}')\nbest_run_id = best_run.run_id\nprint(\"MLflow ID del mejor entrenamiento: \", best_run_id)\nprint(f'Parámetros para el entrenamiento del mejor modelo: {best_run[\"params.hyper-parameters\"]}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"677e93a2-5e37-422f-b3b1-2a91ee868683"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Accuracy del mejor modelo: 0.30027472527472526\nMLflow ID del mejor entrenamiento:  8700b0a2447944c8a1281c97ce2cd35e\nParámetros para el entrenamiento del mejor modelo: {&#39;eta&#39;: 0.38848266999015246, &#39;max_depth&#39;: 13, &#39;min_child_weight&#39;: 20.08262293050307, &#39;missing&#39;: 0.0, &#39;num_class&#39;: 5, &#39;num_round&#39;: 1000, &#39;num_workers&#39;: 3, &#39;objective&#39;: &#39;multi:softmax&#39;, &#39;random_state&#39;: 5, &#39;reg_alpha&#39;: 0.42268704090105524, &#39;reg_lambda&#39;: 0.7640847142362472, &#39;seed&#39;: 5, &#39;subsample&#39;: 0.9458624395316312, &#39;tree_method&#39;: &#39;gpu_hist&#39;, &#39;use_gpu&#39;: True, &#39;verbosity&#39;: 2}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy del mejor modelo: 0.30027472527472526\nMLflow ID del mejor entrenamiento:  8700b0a2447944c8a1281c97ce2cd35e\nParámetros para el entrenamiento del mejor modelo: {&#39;eta&#39;: 0.38848266999015246, &#39;max_depth&#39;: 13, &#39;min_child_weight&#39;: 20.08262293050307, &#39;missing&#39;: 0.0, &#39;num_class&#39;: 5, &#39;num_round&#39;: 1000, &#39;num_workers&#39;: 3, &#39;objective&#39;: &#39;multi:softmax&#39;, &#39;random_state&#39;: 5, &#39;reg_alpha&#39;: 0.42268704090105524, &#39;reg_lambda&#39;: 0.7640847142362472, &#39;seed&#39;: 5, &#39;subsample&#39;: 0.9458624395316312, &#39;tree_method&#39;: &#39;gpu_hist&#39;, &#39;use_gpu&#39;: True, &#39;verbosity&#39;: 2}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Mediante el ID del mejor entrenamiento, se carga el modelo entrenado\nxgb_best_model = f'runs:/{best_run_id}/model'\nmodel = mlflow.spark.load_model(xgb_best_model)\n\n# Se hace predicción con datos de testeo/evaluación\npredict_test = model.transform(test_sdf_prepared)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd1eac84-ac90-401a-b196-7e09539955dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">2021/10/01 13:53:21 INFO mlflow.spark: &#39;runs:/8700b0a2447944c8a1281c97ce2cd35e/model&#39; resolved as &#39;dbfs:/databricks/mlflow-tracking/1528115081293925/8700b0a2447944c8a1281c97ce2cd35e/artifacts/model&#39;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2021/10/01 13:53:21 INFO mlflow.spark: &#39;runs:/8700b0a2447944c8a1281c97ce2cd35e/model&#39; resolved as &#39;dbfs:/databricks/mlflow-tracking/1528115081293925/8700b0a2447944c8a1281c97ce2cd35e/artifacts/model&#39;\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Del Dataframe con la predicción mantenemos solo las columnas de \"VAR_OBJETIVO\", \"prediction\", \"probability\"\npredict_test = predict_test.select(\"VAR_OBJETIVO\", \"prediction\", \"probability\")\n\n# La columna \"probability\" contiene las probabilidades predichas como un vector, se deben transformar a distintas columnas\npredict_test = predict_test.withColumn(\"probability\", vector_to_array(\"probability\")).select([\"VAR_OBJETIVO\", \"prediction\"] + [col(\"probability\")[i] for i in range(5)])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc667bae-e31b-4eda-94b7-bcae64a48b5b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Se transforma el Spark Dataframe a Pandas Dataframe para poder mostrar métricas y matriz de confusión\npredict_test_pd = predict_test.toPandas()\n\n# Se utiliza el método classification_report de sklearn para poder calcular métricas fácilmente\ntarget_names = [\"falsa\", \"sindefinir_fallida\", \"verdadera_nopard\", \"verdadera_pard_noinst\", \"verdadera_pard_inst\"]\nprint_classif = classification_report(predict_test_pd[\"VAR_OBJETIVO\"], predict_test_pd[\"prediction\"], output_dict=True,target_names=target_names)\nmetrics = dict(avg_recall = print_classif[\"macro avg\"][\"recall\"], avg_f1score = print_classif[\"macro avg\"][\"f1-score\"], \n               acc = print_classif[\"accuracy\"], falsa_recall = print_classif[\"falsa\"][\"recall\"],\n               sindef_recall = print_classif[\"sindefinir_fallida\"][\"recall\"], verdnopard_recall = print_classif[\"verdadera_nopard\"][\"recall\"],\n               pardnoinst_recall = print_classif[\"verdadera_pard_noinst\"][\"recall\"], pardinst_recall = print_classif[\"verdadera_pard_inst\"][\"recall\"],\n               falsa_f1score = print_classif[\"falsa\"][\"f1-score\"], sindef_f1score = print_classif[\"sindefinir_fallida\"][\"f1-score\"], \n               verdnopard_f1score = print_classif[\"verdadera_nopard\"][\"f1-score\"], pardnoinst_f1score = print_classif[\"verdadera_pard_noinst\"][\"f1-score\"],\n               pardinst_f1score = print_classif[\"verdadera_pard_inst\"][\"f1-score\"]\n              )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6430b64c-da1a-4b4e-adde-4ce5c88dd47a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Se muestra Dataframe con las métricas\npd.DataFrame(metrics, index=[\"best_acc_tfidf_noweights\"])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"157e5b6e-2e2c-4480-8293-395d4ecfaf00"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[15]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_recall</th>\n      <th>avg_f1score</th>\n      <th>acc</th>\n      <th>falsa_recall</th>\n      <th>sindef_recall</th>\n      <th>verdnopard_recall</th>\n      <th>pardnoinst_recall</th>\n      <th>pardinst_recall</th>\n      <th>falsa_f1score</th>\n      <th>sindef_f1score</th>\n      <th>verdnopard_f1score</th>\n      <th>pardnoinst_f1score</th>\n      <th>pardinst_f1score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>best_acc_tfidf_noweights</th>\n      <td>0.245777</td>\n      <td>0.181353</td>\n      <td>0.300275</td>\n      <td>0.139218</td>\n      <td>0.043784</td>\n      <td>0.732958</td>\n      <td>0.001197</td>\n      <td>0.311726</td>\n      <td>0.212866</td>\n      <td>0.069462</td>\n      <td>0.478354</td>\n      <td>0.00239</td>\n      <td>0.143694</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_recall</th>\n      <th>avg_f1score</th>\n      <th>acc</th>\n      <th>falsa_recall</th>\n      <th>sindef_recall</th>\n      <th>verdnopard_recall</th>\n      <th>pardnoinst_recall</th>\n      <th>pardinst_recall</th>\n      <th>falsa_f1score</th>\n      <th>sindef_f1score</th>\n      <th>verdnopard_f1score</th>\n      <th>pardnoinst_f1score</th>\n      <th>pardinst_f1score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>best_acc_tfidf_noweights</th>\n      <td>0.245777</td>\n      <td>0.181353</td>\n      <td>0.300275</td>\n      <td>0.139218</td>\n      <td>0.043784</td>\n      <td>0.732958</td>\n      <td>0.001197</td>\n      <td>0.311726</td>\n      <td>0.212866</td>\n      <td>0.069462</td>\n      <td>0.478354</td>\n      <td>0.00239</td>\n      <td>0.143694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Se muestra matriz de confusión\ncm1 = confusion_matrix(predict_test_pd[\"VAR_OBJETIVO\"], predict_test_pd[\"prediction\"])\nplt.figure(figsize=(5,5))\nsns.heatmap(cm1, annot=True, fmt=\"d\")\nplt.title('Confusion matrix ')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f15c100-7dce-494b-955c-1a7d65bd981c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[16]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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","removedWidgets":[],"addedWidgets":{},"metadata":{"imageDimensions":{"width":334,"height":333}},"type":"image","arguments":{}},"image/png":{"width":334,"height":333}},"output_type":"display_data","data":{"image/png":"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"}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Text(0.5, 24.0, &#39;Predicted label&#39;)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Text(0.5, 24.0, &#39;Predicted label&#39;)</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"4.4_ML_XGBoost_TFIDF_NoWeights","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1528115081293925}},"nbformat":4,"nbformat_minor":0}
